{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pandas, os, collections\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "os.chdir(\"E:\\Honours\\Master\\Twitter-Learning-Data\\Collections\")\n",
    "\n",
    "BritishDF = pandas.DataFrame.from_csv(\"BritishCollection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=False, max_df=1.0, max_features=None, min_df=0,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
    "\n",
    "vectorizer.fit(BritishDF['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5656822899787154\n"
     ]
    }
   ],
   "source": [
    "sentences = BritishDF['text'].values\n",
    "y = BritishDF['Alignment'].values\n",
    "\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
    "    sentences, y, test_size=0.99, random_state=1000)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences_train)\n",
    "\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)\n",
    "X_train\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7636547577754653\n"
     ]
    }
   ],
   "source": [
    "sentences = BritishDF['text'].values\n",
    "y = BritishDF['Alignment'].values\n",
    "\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
    "    sentences, y, test_size=0.75, random_state=1000)\n",
    "\n",
    "vectorizer2 = CountVectorizer()\n",
    "vectorizer2.fit(sentences_train)\n",
    "\n",
    "X_train = vectorizer2.transform(sentences_train)\n",
    "X_test  = vectorizer2.transform(sentences_test)\n",
    "X_train\n",
    "\n",
    "classifier2 = LogisticRegression()\n",
    "classifier2.fit(X_train, y_train)\n",
    "score = classifier2.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning:\n",
      "\n",
      "from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Change directory to the raw data for testing\n",
    "os.chdir(\"E:\\Honours\\Master\\Twitter-User-Data\\Raw\")\n",
    "#Import user data\n",
    "Username = \"john\"\n",
    "UserData = pandas.DataFrame.from_csv(Username + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Non-Aligned': 1322, 'Labour': 808, 'SNP': 433, 'LibDem': 219, 'Green': 181, 'Conservative': 162, 'DUP': 31, 'UKIP': 30})\n"
     ]
    }
   ],
   "source": [
    "#Vectorize the text\n",
    "UserDataV1 = vectorizer.transform(UserData.text)\n",
    "#Perform prediction of text inputted\n",
    "Classifications = classifier.predict(UserDataV1)\n",
    "#Output a basic overview of the predictions\n",
    "print(collections.Counter(Classifications))\n",
    "#Append original data with model classification\n",
    "UserData[\"Classification\"] = Classifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Non-Aligned': 1158, 'SNP': 594, 'Labour': 535, 'Conservative': 463, 'LibDem': 176, 'Green': 148, 'UKIP': 68, 'DUP': 44})\n"
     ]
    }
   ],
   "source": [
    "#Perform prediction of text inputted\n",
    "UserDataV2 = vectorizer2.transform(UserData.text)\n",
    "Classifications2 = classifier2.predict(UserDataV2)\n",
    "#Output a basic overview of the predictions\n",
    "print(collections.Counter(Classifications2))\n",
    "#Append original data with model classification\n",
    "UserData[\"Classification2\"] = Classifications2\n",
    "\n",
    "#Change directory to the classifications directory for saving\n",
    "os.chdir(\"E:\\Honours\\Master\\Twitter-User-Data\\Classifications\")\n",
    "#Save Classifications to classificaiton directory\n",
    "UserData.to_csv(Username + \"-Classification.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifications = collections.Counter(Classifications)\n",
    "UserCollection = collections.Counter(Classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifications2 = collections.Counter(Classifications2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collections.Counter(Classifications2) == collections.Counter(Classifications):\n",
    "    print(\"Same Result\")\n",
    "else:\n",
    "    print(\"Non Aligned 0.99 - \", Classifications[\"Non-Aligned\"])\n",
    "    print(\"Non Aligned 0.75 - \", Classifications2[\"Non-Aligned\"])  \n",
    "    print(\"Non Aligned Difference - \", Classifications[\"Non-Aligned\"] - Classifications2[\"Non-Aligned\"])\n",
    "    \n",
    "    print(\"Labour 0.99 - \", Classifications[\"Labour\"])\n",
    "    print(\"Labour 0.75 - \", Classifications2[\"Labour\"])  \n",
    "    print(\"Labour Difference - \", Classifications[\"Labour\"] - Classifications2[\"Labour\"])\n",
    "    \n",
    "    print(\"SNP 0.99 - \", Classifications[\"SNP\"])\n",
    "    print(\"SNP 0.75 - \", Classifications2[\"SNP\"])  \n",
    "    print(\"SNP Difference - \", Classifications[\"SNP\"] - Classifications2[\"SNP\"]),\n",
    "    \n",
    "    print(\"Conservative 0.99 - \", Classifications[\"Conservative\"])  \n",
    "    print(\"Conservative 0.75 - \", Classifications2[\"Conservative\"])  \n",
    "    print(\"Conservative Difference - \", Classifications[\"Conservative\"] - Classifications2[\"Conservative\"])\n",
    "    \n",
    "    print(\"DUP 0.99 - \", Classifications[\"DUP\"])\n",
    "    print(\"DUP 0.75 - \", Classifications2[\"DUP\"])  \n",
    "    print(\"DUP Difference - \", Classifications[\"DUP\"] - Classifications2[\"DUP\"])\n",
    "    \n",
    "    print(\"LibDem 0.99 - \", Classifications[\"LibDem\"])\n",
    "    print(\"LibDem 0.75 - \", Classifications2[\"LibDem\"])  \n",
    "    print(\"LibDem Difference - \", Classifications[\"LibDem\"] - Classifications2[\"LibDem\"])\n",
    "    \n",
    "    print(\"Green 0.99 - \", Classifications[\"Green\"])\n",
    "    print(\"Green 0.75 - \", Classifications2[\"Green\"])  \n",
    "    print(\"Green Difference - \", Classifications[\"Green\"] - Classifications2[\"Green\"])\n",
    "    \n",
    "    print(\"UKIP 0.99 - \", Classifications[\"UKIP\"])\n",
    "    print(\"UKIP 0.75 - \", Classifications2[\"UKIP\"])  \n",
    "    print(\"UKIP Difference - \", Classifications[\"UKIP\"] - Classifications2[\"UKIP\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence = vectorizer.transform([\"I hate the EU\"])\n",
    "classifier.predict(Sentence)\n",
    "classifier2.predict(Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Conservative'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"E:\\Honours\\Master\\Speeches\\Republican\\Raw\")\n",
    "Speech = open(\"Trump-Inauguration.txt\").read()\n",
    "Sentence = vectorizer.transform([Speech])\n",
    "classifier.predict(Sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Speech = Speech.replace(\"\\n\", \"\")\n",
    "Speech = Speech.split(\".\")\n",
    "Sentence = vectorizer.transform(Speech)\n",
    "Classification3 = classifier.predict(Sentence)\n",
    "Speech = pandas.DataFrame(Speech)\n",
    "Speech[\"Classification\"] = Classification3\n",
    "Speechcollection = collections.Counter(Classification3)\n",
    "Speech.columns = ['Text', \"Classification\"]\n",
    "#Change directory to the classifications directory for saving\n",
    "os.chdir(\"E:\\Honours\\Master\\Speeches\\Republican\\Classifications\")\n",
    "#Save Classifications to classificaiton directory\n",
    "Speech.to_csv(\"TrumpSpeechBritish-Classification.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Daramithes/6.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly \n",
    "plotly.tools.set_credentials_file(username='Daramithes', api_key='a7V7SdLeEph3UHakJPbs')\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "labels = list(Speechcollection.keys())\n",
    "values = list(Speechcollection.values())\n",
    "colors = [PartyColours[i] for i in labels]\n",
    "\n",
    "\n",
    "trace = go.Pie(labels=labels, values=values,\n",
    "               hoverinfo='label+percent', textinfo='value', \n",
    "               textfont=dict(size=10),\n",
    "               title=\"Trump Inauguration Speech\",\n",
    "               marker=dict(colors=colors, \n",
    "                           line=dict(color='#000000', width=2)))\n",
    "\n",
    "py.iplot([trace], filename='Trump Inauguration Speech Breakdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "PartyColours = {\"Labour\": \"#dc241f\", \n",
    "              \"Conservative\": \"#0087dc\", \n",
    "              \"SNP\": \"#fff95d\", \n",
    "              \"Green\": \"#6ab023\", \n",
    "              \"UKIP\": \"#70147a\", \n",
    "              \"DUP\":\"#d46a4c\", \n",
    "              \"Non-Aligned\": \"#ffffff\", \n",
    "              \"LibDem\": \"#fdbb30\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Daramithes/4.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly \n",
    "plotly.tools.set_credentials_file(username='Daramithes', api_key='a7V7SdLeEph3UHakJPbs')\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "labels = list(UserCollection.keys())\n",
    "values = list(UserCollection.values())\n",
    "colors = [PartyColours[i] for i in labels]\n",
    "\n",
    "\n",
    "trace = go.Pie(labels=labels, values=values,\n",
    "               hoverinfo='label+percent', textinfo='value', \n",
    "               textfont=dict(size=10),\n",
    "               title=\"Johns Twitter Breakdown\",\n",
    "               marker=dict(colors=colors, \n",
    "                           line=dict(color='#000000', width=2)))\n",
    "\n",
    "py.iplot([trace], filename='Johns Twitter Breakdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
