textS$polarity <- textS$sentiment[textS$sentiment$ave_sentiment > 0]
textS$polarity
textS$polarity <- NULL
textS$polarity <- as.character(textS$polarity)
textS$polarity[textS$sentiment$ave_sentiment > 0] <- "Positive"
View(textS)
textS$polarity[textS$sentiment$ave_sentiment < 0] <- "Negative"
textS$polarity[textS$sentiment$ave_sentiment > 0] <- "Positive"
textS$polarity[textS$sentiment$ave_sentiment < 0] <- "Negative"
textS$polarity[textS$sentiment$ave_sentiment = 0] <- "Inconclusive"
textS$polarity[textS$sentiment$ave_sentiment == 0] <- "Inconclusive"
View(textS)
barplot(textS$polarity)
table(textS$polarity)
table <- textS$polarity
barplot(table)
install.packages("ggplot2")
ggplot(table)
require("ggplot2")
ggplot(table)
ggplot(textS$polarity
)
ggplot(data = table)
table <- textS$polarity
table
ggplot(data=table)
table <- table(textS$polarity)
tabke
table
barplot(table)
ggplot(table)
ggplot(as.dataframe(table))
ggplot(as.data.frame(table))
textS$polarity[textS$sentiment$ave_sentiment > 0] <- "Positive"
textS$polarity[textS$sentiment$ave_sentiment < 0] <- "Negative"
textS$polarity[textS$sentiment$ave_sentiment == 0] <- "Inconclusive"
table(textS$polarity)
barplot(table)
textS$polarity[textS$sentiment$ave_sentiment > 0] <- "Positive"
textS$polarity[textS$sentiment$ave_sentiment < 0] <- "Negative"
textS$polarity[textS$sentiment$ave_sentiment == 0] <- "Inconclusive"
table <- table(textS$polarity)
barplot(table)
install.packages("dplyr")
install.packages("tidytext")
install.packages("tidyr")
install.packages("widyr")
install.packages("tidytext")
install.packages("SnowballC")
install.packages("sentimentr")
install.packages("ggplot2")
require(dplyr) #Data manipulation (also included in the tidyverse package)
require(tidytext) #Text mining
require(tidyr) #Spread, separate, unite, text mining (also included in the tidyverse package)
require(widyr) #Use for pairwise correlation
require(tidytext)
require(SnowballC)
require(sentimentr)
#Loading our Dataset
setwd("E:\\Honours")
df <- read.csv('tweets.csv',header=T, na.strings = c(""))
text <- df[,3]
textS <- data.frame(text)
textS$sentiment <- sentiment_by(as.character(textS$text))
highlight(textS$sentiment)
textS$polarity[textS$sentiment$ave_sentiment > 0] <- "Positive"
textS$polarity[textS$sentiment$ave_sentiment < 0] <- "Negative"
textS$polarity[textS$sentiment$ave_sentiment == 0] <- "Inconclusive"
table <- table(textS$polarity)
barplot(table)
sentimentTerms <- extract_sentiment_terms(as.character(textS$text))
setwd("E:\\Honours\tweetsdumper-master\Republican")
setwd("E:\\Honours\tweetsdumper-master\\Republican")
setwd("E:\\Honours\\tweetsdumper-master\\Republican")
file_list <- list.files(path="/*", pattern="*.csv")
file_list <- list.files(pattern="*.csv")
same name as the .csv file
for (i in 1:length(file_list)){
assign(file_list[i],
read.csv(paste(folder, file_list[i], sep=''))
)}
same name as the .csv file
for (i in 1:length(file_list)){
assign(file_list[i],
read.csv(paste(file_list[i], sep=''))
)}
View(SarahPalinUSA_tweets.csv)
View(repkevinhern_tweets.csv)
View(RepDustyJohnson_tweets.csv)
x <- merge(AppSame_tweets.csv, CarlyFiorina_tweets.csv)
View(x)
View(x)
mymergeddata = multmerge()
mymergeddata = multmerge()
mymergeddata = multmerge
csvList <- lapply(list.files("./"), read.csv, stringsAsFactors = F)
## bind them all with do.call
csv <- do.call(csvList, rbind)
do.call("rbind", path="./"
)
do.call("rbind")
do.call("rbind", file_list)
do.call("rbind", list(file_list)
)
x <- do.call("rbind", list(file_list))
View(x)
x <- merge(file_list)
x <- reshape::merge_all(file_list)
import reshape
library("reshape")
install.packages("reshape")
library("reshape")
x <- reshape::merge_all(file_list)
Reduce(function(x, y) merge(x, y, all=TRUE), list(file_list))
x <- Reduce(function(x, y) merge(x, y, all=TRUE), list(file_list))
View(RepCarolMiller_tweets.csv)
for (csv in file_list){
print(csv)
}
list = []
list = List()
list = list()
list <- read.csv(csv)
View(list)
list <- read.csv(csv)}
for (csv in file_list){
list <- read.csv(csv)
}
list = list()
for (csv in file_list){
list.append(read.csv(csv))
}
for (csv in file_list){
list[] <- (read.csv(csv))
}
list = list()
for (csv in file_list){
list[] <- (read.csv(csv))
}
index = 0
for (csv in file_list){
list[index] <- (read.csv(csv))
index = index + 1
}
View(list)
x <- Reduce(function(x, y) merge(x, y, all=TRUE), list(list))
View(x)
View(list)
list[[1]]
list[[1][0]]
list[[1]][0]
your_data_frame <- do.call(rbind,lapply(file_list,read.csv))
View(your_data_frame)
setwd("E:\\Honours\\tweetsdumper-master\\Democratic")
your_data_frame <- do.call(rbind,lapply(file_names,read.csv))
file_list <- list.files(pattern="*.csv")
your_data_frame <- do.call(rbind,lapply(file_names,read.csv))
your_data_frame <- do.call(rbind,lapply(file_list,read.csv))
View(your_data_frame)
setwd("E:\\Honours\\tweetsdumper-master\\Republican")
file_list <- list.files(pattern="*.csv")
your_data_frame <- do.call(rbind,lapply(file_list,read.csv))
setwd("E:\\Honours\\tweetsdumper-master\\Democratic")
file_list <- list.files(pattern="*.csv")
your_data_frame <- do.call(rbind,lapply(file_list,read.csv))
setwd("E:\\Honours\\tweetsdumper-master\\Republican")
file_list <- list.files(pattern="*.csv")
Republican <- do.call(rbind,lapply(file_list,read.csv))
setwd("E:\\Honours\\tweetsdumper-master\\Democratic")
file_list <- list.files(pattern="*.csv")
Democratic <- do.call(rbind,lapply(file_list,read.csv))
drop(your_data_frame)
View(Republican)
Republican['Alignment'] <- "Republican"
Democratic['Alignment'] <- "Democratic"
merge(Democratic, Republican)
test <- merge(Democratic, Republican)
rbind(Democratic, Republican)
x<- rbind(Democratic, Republican)
Data <- rbind(Democratic, Republican)
View(test)
View(x)
text <- data[,3]
text <- Data[,3]
textS <- data.frame(text)
textS$sentiment <- sentiment_by(as.character(textS$text))
highlight(textS$sentiment)
textS$polarity[textS$sentiment$ave_sentiment > 0] <- "Positive"
textS$polarity[textS$sentiment$ave_sentiment < 0] <- "Negative"
textS$polarity[textS$sentiment$ave_sentiment == 0] <- "Inconclusive"
table <- table(textS$polarity)
barplot(table)
sentimentTerms <- extract_sentiment_terms(as.character(textS$text))
buildCorpus <- function(someText){
#Creating our corpus
myCorpus <- Corpus(VectorSource(someText))
#Applying a transformative which changes the tweet to lowercase
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
#Transform our tweets so they have no punctuation
myCorpus <- tm_map(myCorpus, removePunctuation)
#Transform our tweets so they have no numbers.
myCorpus <- tm_map(myCorpus, removeNumbers)
#Create our own function to remove urls
removeURL <- function(x) {
gsub("http[[:alnum:]]*", "", x)
}
#transform our function so that we no longer have urls.
myCorpus <- tm_map(myCorpus, content_transformer(removeURL))
#Since RT is common text, lets add it to our english stopwords
myStopwords <- c(stopwords("english"), "RT","rt")
#remove all instances of rt
myStopwords <- setdiff(myStopwords, c("RT","rt"))
#finally, lets get rid of our stop words
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
#now our text has been processed, lets take away white space
myCorpus <- tm_map(myCorpus, stripWhitespace)
# Return the text corpus
return(myCorpus)
}
}
prepCoprus <- function(x){
#We have to call our previously created function
myCorpus <- buildCorpus(x$text)
#Stemming our corpus
myCorpus <- tm_map(myCorpus, stemDocument)
#We will construct a Term Document Matrix
tdm <- TermDocumentMatrix(myCorpus)
#We will convert
m <- as.matrix(tdm)
v <- sort(rowSums(m), decreasing = TRUE)
#Create a new dataframe using
d <- data.frame(word = names(v), freq = v)
#use gsub to replace any ~ with white space
d$word <- gsub("~", " ", d$word) ##
#Return our word matrix back to our function
return(d)
}
createCloud <- function(dataframe, color, handlex){
x <- subset(dataframe, handle == handlex)
myCorpus <- buildCorpus(x$text)
d <- prepCoprus(x)
wordcloud2(d, figPath = "twitterBird.png", size=1,
fontFamily = "Impact",
color=color,
backgroundColor="Black")
}
fetchwordMatrix <- function(dataframe, handlex){
x <- subset(dataframe, Alignment == handlex)
myCorpus <- buildCorpus(x$text)
d <- prepCoprus(x)
return(d)
}
wordmatrix <- fetchwordMatrix(Data, "Republican")
library("wordcloud2")
install.packages("wordcloud2")
install.packages('tm')
install.packages('SnowballC')
install.packages("SnowballC")
require(SnowballC)
require(sentimentr)
library(tm)
library("snowballC")
library("SnowballC")
install.packages("SnowballC")
library(SnowballC)
wordmatrix <- fetchwordMatrix(Data, "Republican")
corpus <- buildCorpus(Republican$text)
d <- prepCoprus(corpus)
d
fetchwordMatrix <- function(dataframe, ){
myCorpus <- buildCorpus(x$text)
d <- prepCoprus(x)
return(d)
}
fetchwordMatrix <- function(dataframe ){
myCorpus <- buildCorpus(x$text)
d <- prepCoprus(x)
return(d)
}
wordmatrix <- fetchwordMatrix(Republican)
fetchwordMatrix <- function(x ){
myCorpus <- buildCorpus(x$text)
d <- prepCoprus(x)
return(d)
}
wordmatrix <- fetchwordMatrix(Republican)
wordmatrix <- fetchwordMatrix(Democratic)
warning()
View(sentimentTerms)
View(sentimentTerms)
memory.limit()
wordmatrix <- fetchwordMatrix(Democratic[1:"50000"])
wordmatrix <- fetchwordMatrix(Democratic[1:50000])
wordmatrix <- fetchwordMatrix(Democratic[1:50000,])
wordmatrix <- fetchwordMatrix(Democratic[1:30000,])
wordcloud2(wordmatrix, figPath = "twitterBird.png", size=1,
fontFamily = "Impact",
color=color,
backgroundColor="Black")
}
wordcloud2(wordmatrix, figPath = "twitterBird.png", size=1,
fontFamily = "Impact",
color=color,
backgroundColor="Black")
library(wordcloud2)
wordcloud2(wordmatrix, figPath = "twitterBird.png", size=1,
fontFamily = "Impact",
color=color,
backgroundColor="Black")
install.packages("base64enc")
wordcloud2(wordmatrix, figPath = "twitterBird.png", size=1,
fontFamily = "Impact",
color=color,
backgroundColor="Black")
wordcloud2(wordmatrix, figPath = "twitterBird.png", size=1,
fontFamily = "Impact",
backgroundColor="Black")
wordcloud2(wordmatrix, figPath = "twitterBird.png", size=1,
fontFamily = "Impact",
color="skyblue",
backgroundColor="Black")
x <- wordcloud2(wordmatrix, figPath = "twitterBird.png", size=1,
fontFamily = "Impact",
color="skyblue",
backgroundColor="Black")
x
View(x)
x <- wordcloud2(wordmatrix, figPath = "twitterBird.png",
fontFamily = "Impact",
color="skyblue",
backgroundColor="Black")
wordcloud2(wordmatrix, figPath = "twitterBird.png",
color="skyblue",
backgroundColor="Black")
wordcloud2(wordmatrix)
wordcloud2(wordmatrix, figPath = "twitterBird.png")
wordcloud2(wordmatrix, figPath = "twitterBird.png")
View(x)
View(wordmatrix)
wordcloud2(wordmatrix, figPath = "twitterBird.png")
wordcloud2(wordmatrix, figPath = "twitterBird.png")
wordcloud2(wordmatrix, figPath = "twitterBird.png")
wordcloud2(wordmatrix)
wordmatrix <- fetchwordMatrix(Republican[1:30000,])
wordcloud2(wordmatrix)
wordmatrix[1:10]
wordmatrix[1:10,]
setwd("E:\\Honours\\tweetsdumper-master\\Republican")
file_list <- list.files(pattern="*.csv")
Republican <- do.call(rbind,lapply(file_list,read.csv))
Republican['Alignment'] <- 1
setwd("E:\\Honours\\tweetsdumper-master\\Democratic")
file_list <- list.files(pattern="*.csv")
Democratic <- do.call(rbind,lapply(file_list,read.csv))
Democratic['Alignment'] <- 0
Data <- rbind(Democratic, Republican)
require(dplyr) #Data manipulation (also included in the tidyverse package)
require(tidytext) #Text mining
require(tidyr) #Spread, separate, unite, text mining (also included in the tidyverse package)
require(widyr) #Use for pairwise correlation
require(tidytext)
require(SnowballC)
require(sentimentr)
library(tm)
library(e1071)
library(caret)
install.packages("dplyr")
install.packages("tidytext")
install.packages("tidyr")
install.packages("widyr")
install.packages("tidytext")
install.packages("SnowballC")
install.packages("sentimentr")
install.packages("ggplot2")
install.packages("caret")
setwd("E:\\Honours\\tweetsdumper-master\\Republican")
file_list <- list.files(pattern="*.csv")
Republican <- do.call(rbind,lapply(file_list,read.csv))
setwd("E:\\Honours\\tweetsdumper-master\\Republican")
getwd()
setwd("i:\\Honours\\tweetsdumper-master\\Democratic")
setwd("I:\\Honours\\tweetsdumper-master\\Republican")
file_list <- list.files(pattern="*.csv")
Republican <- do.call(rbind,lapply(file_list,read.csv))
Republican['Alignment'] <- 1
setwd("i:\\Honours\\tweetsdumper-master\\Democratic")
file_list <- list.files(pattern="*.csv")
Democratic <- do.call(rbind,lapply(file_list,read.csv))
Democratic['Alignment'] <- 0
Data <- rbind(Democratic, Republican)
buildCorpus <- function(someText){
#Creating our corpus
myCorpus <- Corpus(VectorSource(someText))
#Applying a transformative which changes the tweet to lowercase
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
#Transform our tweets so they have no punctuation
myCorpus <- tm_map(myCorpus, removePunctuation)
#Transform our tweets so they have no numbers.
myCorpus <- tm_map(myCorpus, removeNumbers)
#Create our own function to remove urls
removeURL <- function(x) {
gsub("http[[:alnum:]]*", "", x)
}
#transform our function so that we no longer have urls.
myCorpus <- tm_map(myCorpus, content_transformer(removeURL))
#Since RT is common text, lets add it to our english stopwords
myStopwords <- c(stopwords("english"), "RT","rt")
#remove all instances of rt
myStopwords <- setdiff(myStopwords, c("RT","rt"))
#finally, lets get rid of our stop words
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
#now our text has been processed, lets take away white space
myCorpus <- tm_map(myCorpus, stripWhitespace)
# Return the text corpus
return(myCorpus)
}
Data <- Data[,c(3,8)]
myCorpus <- buildCorpus(Data$text)
dtm <- DocumentTermMatrix(myCorpus)
inTrain <- createDataPartition(
y=Data$Alignment, p=0.5, list=FALSE)
train <- dtm[inTrain,]
test <- dtm[-inTrain,]
View(Data)
Data <- Data[,c(2,1)]
myCorpus <- buildCorpus(Data$text)
dtm <- DocumentTermMatrix(myCorpus)
require(dplyr) #Data manipulation (also included in the tidyverse package)
require(tidytext) #Text mining
require(tidyr) #Spread, separate, unite, text mining (also included in the tidyverse package)
require(widyr) #Use for pairwise correlation
require(tidytext)
require(SnowballC)
require(sentimentr)
library(tm)
library(e1071)
library(caret)
install.packages("caret")
require(dplyr) #Data manipulation (also included in the tidyverse package)
require(tidytext) #Text mining
require(tidyr) #Spread, separate, unite, text mining (also included in the tidyverse package)
require(widyr) #Use for pairwise correlation
require(tidytext)
require(SnowballC)
require(sentimentr)
library(tm)
library(e1071)
library(caret)
myCorpus <- buildCorpus(Data$text)
dtm <- DocumentTermMatrix(myCorpus)
inTrain <- createDataPartition(
y=Data$Alignment, p=0.5, list=FALSE)
train <- dtm[inTrain,]
test <- dtm[-inTrain,]
trainLabels <- Data[inTrain,]$Alignment
testLabels <- Data[-inTrain,]$Alignment
freqTerms <- findFreqTerms(train,5)
reducedTrain <- train[,freqTerms]
reducedTest <- test[,freqTerms]
dim(train); dim(reducedTrain)
dim(test); dim(reducedTest)
convert_counts <- function(x){
x <- ifelse(x >0,1,0)
x <- factor(x,levels = c(0,1),labels = c("No","Yes"))
return(x)
}
reducedTrainU <- apply(reducedTrain, MARGIN =2, FUN=convert_counts)
Democratic <- Democratic[1,3500]
Republican <- Republican[1,3500]
file_list <- list.files(pattern="*.csv")
Democratic <- do.call(rbind,lapply(file_list,read.csv))
Democratic['Alignment'] <- 0
Democratic <- Democratic[1,3500,]
setwd("i:\\Honours\\tweetsdumper-master\\Democratic")
file_list <- list.files(pattern="*.csv")
Democratic <- do.call(rbind,lapply(file_list,read.csv))
Democratic <- Democratic[1:3500,]
setwd("I:\\Honours\\tweetsdumper-master\\Republican")
file_list <- list.files(pattern="*.csv")
Republican <- do.call(rbind,lapply(file_list,read.csv))
Republican['Alignment'] <- 1
Republican <- Republican[1:3500,]
Democratic['Alignment'] <- 0
Data <- rbind(Democratic, Republican)
Data <- Data[,c(8,3)]
myCorpus <- buildCorpus(Data$text)
dtm <- DocumentTermMatrix(myCorpus)
inTrain <- createDataPartition(
y=Data$Alignment, p=0.5, list=FALSE)
train <- dtm[inTrain,]
test <- dtm[-inTrain,]
trainLabels <- Data[inTrain,]$Alignment
testLabels <- Data[-inTrain,]$Alignment
freqTerms <- findFreqTerms(train,5)
reducedTrain <- train[,freqTerms]
reducedTest <- test[,freqTerms]
dim(train); dim(reducedTrain)
dim(test); dim(reducedTest)
convert_counts <- function(x){
x <- ifelse(x >0,1,0)
x <- factor(x,levels = c(0,1),labels = c("No","Yes"))
return(x)
}
reducedTrainU <- apply(reducedTrain, MARGIN =2, FUN=convert_counts)
reducedTestU <- apply(reducedTest,MARGIN = 2,FUN = convert_counts)
bayesModel <- naiveBayes(reducedTrainU,trainLabels)
predictions <- predict(bayesModel,reducedTestU)
accuracy = sum(diag(as.matrix(table(
predictions,testLabels))))/length(predictions)*100
cat("The prediction model is ", accuracy, "% Accurate!")
bayesModel <- naiveBayes(train,trainLabels)
predictions <- predict(bayesModel,test)
